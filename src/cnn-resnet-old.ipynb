{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import resnet_model\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training data set\n",
    "train = pd.read_json('../data/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              band_1  \\\n",
      "0  [-27.878360999999998, -27.15416, -28.668615, -...   \n",
      "1  [-12.242375, -14.920304999999999, -14.920363, ...   \n",
      "2  [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
      "3  [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
      "4  [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
      "\n",
      "                                              band_2        id inc_angle  \\\n",
      "0  [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913   43.9239   \n",
      "1  [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd   38.1562   \n",
      "2  [-24.870956, -24.092632, -20.653963, -19.41104...  58b2aaa0   45.2859   \n",
      "3  [-27.889421, -27.519794, -27.165262, -29.10350...  4cfc3a18   43.8306   \n",
      "4  [-27.206915, -30.259186, -30.259186, -23.16495...  271f93f4   35.6256   \n",
      "\n",
      "   is_iceberg  \n",
      "0           0  \n",
      "1           0  \n",
      "2           1  \n",
      "3           0  \n",
      "4           0  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 band_1  \\\n",
<<<<<<< HEAD:src/cnn-resnet-old.ipynb
      "386   [-24.598627, -22.610989, -20.672844, -19.91712...   \n",
      "1251  [-14.8766, -14.797337, -15.368505, -15.538882,...   \n",
      "429   [-14.248891, -15.300611, -17.21739, -17.885916...   \n",
      "1005  [-19.860071, -19.443127, -18.789801, -19.44324...   \n",
      "907   [-25.730068, -20.308781, -17.771362, -19.01436...   \n",
      "\n",
      "                                                 band_2        id inc_angle  \\\n",
      "386   [-28.245432, -23.658751, -25.109818, -27.52135...  ee35ad62   39.2166   \n",
      "1251  [-26.082706, -23.583992, -21.645849, -22.56105...  fe8a6bf9   38.1572   \n",
      "429   [-27.782763, -28.942654, -26.13913, -23.565849...  9e25e53e   40.3973   \n",
      "1005  [-29.12228, -26.939449, -27.267315, -29.54624,...  5d58d936   38.8537   \n",
      "907   [-28.424042, -24.642963, -25.16959, -24.391272...  e87b80d6   41.4339   \n",
      "\n",
      "      is_iceberg     order  \n",
      "386            1  0.000836  \n",
      "1251           0  0.000955  \n",
      "429            0  0.001498  \n",
      "1005           1  0.002447  \n",
      "907            1  0.003205  \n"
=======
      "1069  [-17.634449, -17.843834, -17.843834, -19.34320...   \n",
      "1460  [-24.066139, -22.665459, -23.851814, -24.51181...   \n",
      "1105  [-19.78277, -24.363373, -23.233799, -18.104897...   \n",
      "623   [-28.147009, -25.554382, -24.500305, -26.75444...   \n",
      "306   [-23.995512, -22.656616, -20.636129, -20.31443...   \n",
      "\n",
      "                                                 band_2        id inc_angle  \\\n",
      "1069  [-27.49276, -23.864433, -23.864433, -26.292953...  0b2e007c    32.785   \n",
      "1460  [-22.665382, -24.286121, -30.086891, -26.28025...  3f6778c5   33.6523   \n",
      "1105  [-24.608006, -25.386421, -27.19001, -26.862257...  3f01fa55   39.2166   \n",
      "623   [-30.276115, -26.754341, -26.754391, -24.25566...  0d3b11df   40.2484   \n",
      "306   [-24.2402, -25.294371, -26.822178, -27.517464,...  46c85664    43.951   \n",
      "\n",
      "      is_iceberg     order  \n",
      "1069           1  0.000442  \n",
      "1460           1  0.000721  \n",
      "1105           1  0.003224  \n",
      "623            0  0.003377  \n",
      "306            1  0.005938  \n"
>>>>>>> 2020c18c72af5341319fe7bc1a9fd0d4caa0cc58:src/cnn-resnet.ipynb
     ]
    }
   ],
   "source": [
    "order_num = np.random.rand(train.shape[0])\n",
    "train['order'] = order_num\n",
    "train.sort_values('order', axis=0, inplace=True)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 2)\n"
     ]
    }
   ],
   "source": [
    "raw_y = train['is_iceberg'].tolist()\n",
    "tensor_y = tf.one_hot(raw_y, depth=2)\n",
    "with tf.Session() as sess:\n",
    "    total_y = np.array(sess.run(tensor_y))\n",
    "print(total_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 11250)\n"
     ]
    }
   ],
   "source": [
    "raw_x_1 = np.array(train['band_1'].tolist())\n",
    "raw_x_2 = np.array(train['band_2'].tolist())\n",
    "total_x = np.concatenate((raw_x_1, raw_x_2), axis = 1)\n",
    "#total_x = raw_x_1\n",
    "print(total_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 11250)\n",
      "(1304, 11250)\n",
      "(1304, 2)\n"
     ]
    }
   ],
   "source": [
    "dev_x = total_x[0:300,:]\n",
    "dev_y = total_y[0:300,:]\n",
    "print(dev_x.shape)\n",
    "train_x = total_x[300:,:]\n",
    "train_y = total_y[300:,:]\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MiniBatch(object):\n",
    "    def __init__(self, x, y, batch_size):\n",
    "        self.generator = self.slice_random(x, y, batch_size)\n",
    "    \n",
    "    def next_batch(self):\n",
    "        try:\n",
    "            return(next(self.generator))\n",
    "        except StopIteration as e:\n",
    "            return None, None\n",
    "        \n",
    "    @staticmethod    \n",
    "    def slice_random(X, Y, mini_batch_size):\n",
    "        tmp_X = X.copy()\n",
    "        tmp_Y = Y.copy()\n",
    "        cur_index = 0\n",
    "        while(tmp_X.shape[0]>0):\n",
    "            pick_size = tmp_X.shape[0] if tmp_X.shape[0]<mini_batch_size else mini_batch_size\n",
    "            mini_batch_x = tmp_X[cur_index:cur_index + pick_size,:]\n",
    "            mini_batch_y = tmp_Y[cur_index:cur_index + pick_size,:]\n",
    "            cur_index += pick_size\n",
    "            yield mini_batch_x, mini_batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('reshape'):\n",
    "    x_in = tf.placeholder(tf.float32)\n",
    "    y_in = tf.placeholder(tf.float32)\n",
    "    x = tf.image.resize_image_with_crop_or_pad(tf.reshape(x_in, [-1,75,75, 2]), 256, 256) \n",
    "    y = tf.reshape(y_in, [-1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('resnet'):\n",
    "    y_generator = resnet_model.imagenet_resnet_v2(18, 2, 'channels_last')\n",
    "    y_ = y_generator(x, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('cost'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(10E-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD:src/cnn-resnet-old.ipynb
=======
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal training\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     tf.add_to_collection('accuracy', accuracy)\n",
    "#     tf.add_to_collection('y_', y_)\n",
    "#     tf.add_to_collection('x_in', x_in)\n",
    "#     tf.add_to_collection('y_in', y_in)\n",
    "#     # writer = tf.summary.FileWriter('./logs',sess.graph)\n",
    "#     for i in range(1001):\n",
    "#         minibatch = MiniBatch(train_x, train_y, 64)\n",
    "#         x_batch,y_batch = minibatch.next_batch()\n",
    "#         if x_batch is None or x_batch.shape[0]<64:\n",
    "#             minibatch = MiniBatch(train_x, train_y, 64)\n",
    "#             x_batch,y_batch = minibatch.next_batch()\n",
    "#         # print('minibatch size {} and {}'.format(x_batch.shape, y_batch.shape))\n",
    "#         if i%100 == 0:\n",
    "#             testMiniBatch = MiniBatch(dev_x, dev_y, 64)\n",
    "#             x_batch_test, y_batch_test = testMiniBatch.next_batch()\n",
    "#             if x_batch_test is None or x_batch_test.shape[0]<64:\n",
    "#                 testMiniBatch = MiniBatch(dev_x, dev_y, 64)\n",
    "#                 x_batch_test, y_batch_test = testMiniBatch.next_batch()\n",
    "#             train_accuracy = accuracy.eval(session=sess,\n",
    "#                                             feed_dict={\n",
    "#                                                 x_in:x_batch_test, y_in:y_batch_test\n",
    "#                                             })\n",
    "#             print('step {}, training accuracy {}'.format(i, train_accuracy))\n",
    "#             print('test accuracy {}'.format(accuracy.eval(session=sess, feed_dict={x_in: dev_x , y_in: dev_y})))\n",
    "#             saver = tf.train.Saver()\n",
    "#             saved_path = saver.save(sess, './models/{}.ckpt'.format(i))\n",
    "#             print('model saved to {}'.format(saved_path))\n",
    "#         sess.run(optimizer, feed_dict={x_in:x_batch, y_in:y_batch})\n",
    "#     # writer.close()\n",
    "#     print('test accuracy {}'.format(accuracy.eval(session=sess, feed_dict={x_in: dev_x , y_in: dev_y})))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> 2020c18c72af5341319fe7bc1a9fd0d4caa0cc58:src/cnn-resnet.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD:src/cnn-resnet-old.ipynb
      "step 0, training accuracy 0.53125\n",
      "test accuracy 0.4466666579246521\n",
      "model saved to ./models/0.ckpt\n",
      "step 100, training accuracy 0.59375\n",
      "test accuracy 0.6566666960716248\n",
      "model saved to ./models/100.ckpt\n",
      "step 200, training accuracy 0.59375\n",
      "test accuracy 0.6600000262260437\n",
      "model saved to ./models/200.ckpt\n",
      "step 300, training accuracy 0.578125\n",
      "test accuracy 0.6566666960716248\n",
      "model saved to ./models/300.ckpt\n",
      "step 400, training accuracy 0.578125\n",
      "test accuracy 0.6566666960716248\n",
      "model saved to ./models/400.ckpt\n"
=======
      "step 0, training accuracy 0.5\n",
      "model saved to ./models/0.ckpt\n",
      "step 10, training accuracy 0.765625\n",
      "model saved to ./models/10.ckpt\n",
      "step 20, training accuracy 0.984375\n",
      "model saved to ./models/20.ckpt\n",
      "step 30, training accuracy 1.0\n",
      "model saved to ./models/30.ckpt\n"
>>>>>>> 2020c18c72af5341319fe7bc1a9fd0d4caa0cc58:src/cnn-resnet.ipynb
     ]
    }
   ],
   "source": [
    "# training with 2 image\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf.add_to_collection('accuracy', accuracy)\n",
    "    tf.add_to_collection('y_', y_)\n",
    "    tf.add_to_collection('x_in', x_in)\n",
    "    tf.add_to_collection('y_in', y_in)\n",
<<<<<<< HEAD:src/cnn-resnet-old.ipynb
    "    tf.add_to_collection('cost', cost)\n",
    "    # writer = tf.summary.FileWriter('./logs',sess.graph)\n",
=======
    "    minibatch = MiniBatch(train_x, train_y, 64)\n",
    "    x_batch,y_batch = minibatch.next_batch()\n",
>>>>>>> 2020c18c72af5341319fe7bc1a9fd0d4caa0cc58:src/cnn-resnet.ipynb
    "    for i in range(1001):\n",
    "        if i%10 == 0:\n",
    "            train_accuracy = accuracy.eval(session=sess,\n",
    "                                            feed_dict={\n",
    "                                                x_in:x_batch, y_in:y_batch\n",
    "                                            })\n",
    "            print('step {}, training accuracy {}'.format(i, train_accuracy))\n",
    "            saver = tf.train.Saver()\n",
    "            saved_path = saver.save(sess, './models/{}.ckpt'.format(i))\n",
    "            print('model saved to {}'.format(saved_path))\n",
    "        sess.run(optimizer, feed_dict={x_in:x_batch, y_in:y_batch})\n",
    "    print('test accuracy {}'.format(accuracy.eval(session=sess, feed_dict={x_in: dev_x , y_in: dev_y})))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:src/cnn-resnet-old.ipynb
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/400.ckpt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-70d7ee7b72f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/400.ckpt.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./models/400.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1E-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.import_meta_graph('./models/400.ckpt.meta')\n",
    "    saver.restore(sess, './models/400.ckpt')\n",
    "    cost = tf.get_collection('cost')[0]\n",
    "    optimizer = tf.train.AdamOptimizer(1E-5).minimize(cost)\n",
    "    accuracy = tf.get_collection('accuracy')[0]\n",
    "    x_in = tf.get_collection('x_in')[0]\n",
    "    y_in = tf.get_collection('y_in')[0]\n",
    "    y_ = tf.get_collection('y_')[0]\n",
    "    # writer = tf.summary.FileWriter('./logs',sess.graph)\n",
    "    for i in range(1001):\n",
    "        minibatch = MiniBatch(train_x, train_y, 64)\n",
    "        x_batch,y_batch = minibatch.next_batch()\n",
    "        if x_batch is None or x_batch.shape[0]<64:\n",
    "            minibatch = MiniBatch(train_x, train_y, 64)\n",
    "            x_batch,y_batch = minibatch.next_batch()\n",
    "        # print('minibatch size {} and {}'.format(x_batch.shape, y_batch.shape))\n",
    "        if i%100 == 0:\n",
    "            testMiniBatch = MiniBatch(dev_x, dev_y, 64)\n",
    "            x_batch_test, y_batch_test = testMiniBatch.next_batch()\n",
    "            if x_batch_test is None or x_batch_test.shape[0]<64:\n",
    "                testMiniBatch = MiniBatch(dev_x, dev_y, 64)\n",
    "                x_batch_test, y_batch_test = testMiniBatch.next_batch()\n",
    "            train_accuracy = accuracy.eval(session=sess,\n",
    "                                            feed_dict={\n",
    "                                                x_in:x_batch_test, y_in:y_batch_test\n",
    "                                            })\n",
    "            print('step {}, training accuracy {}'.format(i, train_accuracy))\n",
    "            print('test accuracy {}'.format(accuracy.eval(session=sess, feed_dict={x_in: dev_x , y_in: dev_y})))\n",
    "            saver = tf.train.Saver()\n",
    "            saved_path = saver.save(sess, './models/{}.ckpt'.format(i))\n",
    "            print('model saved to {}'.format(saved_path))\n",
    "        sess.run(optimizer, feed_dict={x_in:x_batch, y_in:y_batch})\n",
    "    # writer.close()\n",
=======
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch gradient descent without random shuffle\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf.add_to_collection('accuracy', accuracy)\n",
    "    tf.add_to_collection('y_', y_)\n",
    "    tf.add_to_collection('x_in', x_in)\n",
    "    tf.add_to_collection('y_in', y_in)\n",
    "    # epoch\n",
    "    batch_size = 64\n",
    "    for i in range(1001):\n",
    "        for j in range(np.floor(train_x.shape[0] / 64)):\n",
    "            x_batch = train_x[j * batch_size: (j+1) * batch_size]\n",
    "            y_batch = train_y[j * batch_size: (j+1) * batch_size]\n",
    "            sess.run(optimizer, feed_dict={x_in:x_batch, y_in:y_batch})\n",
    "        # print accuracy after each epoch\n",
    "        train_accuracy = accuracy.eval(session=sess,\n",
    "                                        feed_dict={\n",
    "                                            x_in:x_batch, y_in:y_batch\n",
    "                                        })\n",
    "        print('epoch {}, training accuracy {}'.format(i, train_accuracy))\n",
    "        saver = tf.train.Saver()\n",
    "        saved_path = saver.save(sess, './models/{}.ckpt'.format(i))\n",
    "        print('model saved to {}'.format(saved_path))\n",
>>>>>>> 2020c18c72af5341319fe7bc1a9fd0d4caa0cc58:src/cnn-resnet.ipynb
    "    print('test accuracy {}'.format(accuracy.eval(session=sess, feed_dict={x_in: dev_x , y_in: dev_y})))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:src/cnn-resnet-old.ipynb
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "a = [0,1,2,3,4,5]\n",
    "print(a[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/30.ckpt\n",
      "model restored\n",
      "test accuracy 0.515625\n"
     ]
    }
   ],
>>>>>>> 2020c18c72af5341319fe7bc1a9fd0d4caa0cc58:src/cnn-resnet.ipynb
   "source": [
    "# with tf.Session() as sess:\n",
    "#     saver = tf.train.import_meta_graph('./models/30.ckpt.meta')\n",
    "#     saver.restore(sess, './models/30.ckpt')\n",
    "#     accuracy = tf.get_collection('accuracy')[0]\n",
    "#     x_in = tf.get_collection('x_in')[0]\n",
    "#     y_in = tf.get_collection('y_in')[0]\n",
    "#     print('model restored')\n",
    "#     print('test accuracy {}'.format(accuracy.eval(session=sess, feed_dict={x_in:dev_x[0:64], y_in:dev_y[0:64]})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     writer = tf.summary.FileWriter('../logs',sess.graph)\n",
    "#     accuracy_res = accuracy.eval(session=sess, feed_dict={x_in:train_x[0:10], y_in:train_y[0:10]})\n",
    "#     print(accuracy_res)\n",
    "#     writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
