{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training data set\n",
    "train = pd.read_json('../input/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              band_1  \\\n",
      "0  [-27.878360999999998, -27.15416, -28.668615, -...   \n",
      "1  [-12.242375, -14.920304999999999, -14.920363, ...   \n",
      "2  [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
      "3  [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
      "4  [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
      "\n",
      "                                              band_2        id inc_angle  \\\n",
      "0  [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913   43.9239   \n",
      "1  [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd   38.1562   \n",
      "2  [-24.870956, -24.092632, -20.653963, -19.41104...  58b2aaa0   45.2859   \n",
      "3  [-27.889421, -27.519794, -27.165262, -29.10350...  4cfc3a18   43.8306   \n",
      "4  [-27.206915, -30.259186, -30.259186, -23.16495...  271f93f4   35.6256   \n",
      "\n",
      "   is_iceberg  \n",
      "0           0  \n",
      "1           0  \n",
      "2           1  \n",
      "3           0  \n",
      "4           0  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 band_1  \\\n",
      "797   [-25.211447, -23.585413, -21.033905, -20.13462...   \n",
      "1440  [-31.97308, -29.474361, -29.050629, -29.050684...   \n",
      "728   [-23.622217, -21.182369, -21.182405, -19.71780...   \n",
      "1580  [-17.248318, -16.214254, -15.532733, -15.95249...   \n",
      "1550  [-24.592573, -24.592529, -24.592484, -25.67959...   \n",
      "\n",
      "                                                 band_2        id inc_angle  \\\n",
      "797   [-24.019733, -26.013855, -24.019867, -24.24555...  b522fe03   35.6334   \n",
      "1440  [-24.865326, -26.5518, -27.195549, -30.886093,...  9fabab12    39.234   \n",
      "728   [-23.390581, -24.356712, -22.945129, -23.16507...  f8c7b912   45.3362   \n",
      "1580  [-21.718636, -24.217484, -24.443178, -25.15756...  5f49ea3b        na   \n",
      "1550  [-26.594877, -27.987553, -29.64699, -28.373562...  de13af0f        na   \n",
      "\n",
      "      is_iceberg     order  \n",
      "797            1  0.001107  \n",
      "1440           1  0.001367  \n",
      "728            1  0.001612  \n",
      "1580           0  0.001933  \n",
      "1550           0  0.002020  \n"
     ]
    }
   ],
   "source": [
    "order_num = np.random.rand(train.shape[0])\n",
    "train['order'] = order_num\n",
    "train.sort_values('order', axis=0, inplace=True)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 2)\n"
     ]
    }
   ],
   "source": [
    "raw_y = train['is_iceberg'].tolist()\n",
    "tensor_y = tf.one_hot(raw_y, depth=2)\n",
    "with tf.Session() as sess:\n",
    "    total_y = np.array(sess.run(tensor_y))\n",
    "print(total_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 5625)\n"
     ]
    }
   ],
   "source": [
    "raw_x_1 = np.array(train['band_1'].tolist())\n",
    "raw_x_2 = np.array(train['band_2'].tolist())\n",
    "total_x = np.concatenate((raw_x_1, raw_x_2), axis = 1)\n",
    "total_x = raw_x_1\n",
    "print(total_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 5625)\n",
      "(1304, 5625)\n",
      "(1304, 2)\n"
     ]
    }
   ],
   "source": [
    "dev_x = total_x[0:300,:]\n",
    "dev_y = total_y[0:300,:]\n",
    "print(dev_x.shape)\n",
    "train_x = total_x[300:,:]\n",
    "train_y = total_y[300:,:]\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MiniBatch(object):\n",
    "    def __init__(self, x, y, batch_size):\n",
    "        self.generator = self.slice_random(x, y, batch_size)\n",
    "    \n",
    "    def next_batch(self):\n",
    "        try:\n",
    "            return(next(self.generator))\n",
    "        except StopIteration as e:\n",
    "            return None, None\n",
    "        \n",
    "    @staticmethod    \n",
    "    def slice_random(X, Y, mini_batch_size):\n",
    "        tmp_X = X.copy()\n",
    "        tmp_Y = Y.copy()\n",
    "        cur_index = 0\n",
    "        while(tmp_X.shape[0]>0):\n",
    "            pick_size = tmp_X.shape[0] if tmp_X.shape[0]<mini_batch_size else mini_batch_size\n",
    "            mini_batch_x = tmp_X[cur_index:cur_index + pick_size,:]\n",
    "            mini_batch_y = tmp_Y[cur_index:cur_index + pick_size,:]\n",
    "            cur_index += pick_size\n",
    "            yield mini_batch_x, mini_batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "test_mini_batch = MiniBatch(dev_x, dev_y, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[-25.211447, -23.585413, -21.033905, ..., -22.782347, -22.042744,\n",
      "        -21.867332],\n",
      "       [-31.97308 , -29.474361, -29.050629, ..., -28.652031, -27.541685,\n",
      "        -30.395088],\n",
      "       [-23.622217, -21.182369, -21.182405, ..., -19.87192 , -21.185534,\n",
      "        -19.282896],\n",
      "       ..., \n",
      "       [-18.457067, -18.005821, -16.045731, ..., -18.012941, -16.411083,\n",
      "        -18.464401],\n",
      "       [-16.543774, -16.734745, -21.171787, ..., -19.176027, -19.83946 ,\n",
      "        -19.049356],\n",
      "       [-20.029573, -20.029573, -24.320618, ..., -26.20401 , -29.431421,\n",
      "        -25.081745]]), array([[ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(test_mini_batch.next_batch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('reshape'):\n",
    "    x_in = tf.placeholder(tf.float32)\n",
    "    y_in = tf.placeholder(tf.float32)\n",
    "    x = tf.reshape(x_in, [-1,75,75,1])\n",
    "    y = tf.reshape(y_in, [-1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input N*H*W*C\n",
    "# output N*H*W*F\n",
    "def conv_layer(input_data, hight, width, channel, feature, pool_window, name):\n",
    "    with tf.name_scope(name):\n",
    "        f = tf.get_variable('f'+name, [width,hight,channel,feature], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         f = tf.Variable(dtype=tf.float32, \n",
    "#                         initial_value=tf.random_normal([width,hight,channel,feature], mean=0, stddev=0.1), \n",
    "#                         expected_shape=[width,hight,channel,feature])\n",
    "#         b = tf.Variable(dtype=tf.float32,\n",
    "#                         initial_value=tf.random_normal([feature], mean=0.1, stddev=0.1),\n",
    "#                         expected_shape=[feature])\n",
    "        c = tf.nn.conv2d(input_data, filter=f, strides=[1,1,1,1], padding='SAME')\n",
    "        a = tf.nn.relu(c)\n",
    "        p = tf.nn.pool(a, pool_window, strides=pool_window, pooling_type='MAX', padding='SAME')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input N*W\n",
    "# output N*W1\n",
    "def fc_layer(input_data, this_feature, next_feature, name, activate=True):\n",
    "    with tf.name_scope(name):\n",
    "        if activate:\n",
    "            return tf.contrib.layers.fully_connected(input_data, next_feature)\n",
    "        else:\n",
    "            return tf.contrib.layers.fully_connected(input_data, next_feature, activation_fn=None)\n",
    "#         w = tf.Variable(dtype=tf.float32,\n",
    "#                        initial_value=tf.random_normal([this_feature, next_feature], mean=0, stddev=0.1),\n",
    "#                        expected_shape=[this_feature, next_feature])\n",
    "# #         b = tf.Variable(dtype=tf.float32,\n",
    "# #                        initial_value=tf.random_normal([next_feature], mean=0.1, stddev=0.1), \n",
    "# #                        expected_shape=[next_feature])\n",
    "#         b = tf.constant(0.1, shape=[next_feature])\n",
    "#         a = tf.matmul(input_data, w) + b\n",
    "#         if activate:\n",
    "#             return tf.nn.relu(a)\n",
    "#         else:\n",
    "#             return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn():\n",
    "    l1 = conv_layer(x, 5, 5, 1, 8, [5,5], 'conv_1')\n",
    "    l2 = conv_layer(l1, 5, 5, 8, 16, [3,3], 'conv_2')\n",
    "    l3 = fc_layer(tf.reshape(l2, [-1, 5*5*16]), 5*5*16, 128, 'fc_3')\n",
    "    l4 = fc_layer(l3, 128, 2, 'fc_4', False)\n",
    "    return l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('cost'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "minibatch = MiniBatch(train_x, train_y, 50)\n",
    "x1,y1 = minibatch.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 5625)\n",
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(x1.shape)\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('./logs',sess.graph)\n",
    "    # test_res = accuracy.eval(session=sess, feed_dict={x_in:x1, y_in:y1})\n",
    "    test_res = sess.run(y_, feed_dict={x_in:x1, y_in:y1})\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 29.61538506  -3.00328088]\n",
      " [ 30.11032295  -6.09710741]\n",
      " [ 41.85795212  -1.74087083]\n",
      " [ 40.64450455  -4.68768644]\n",
      " [ 28.70099068  -1.87916088]\n",
      " [ 36.81660843  -2.91621351]\n",
      " [ 36.3024826   -3.18376279]\n",
      " [ 40.56246948  -3.41964722]\n",
      " [ 36.04766083  -2.75838375]\n",
      " [ 41.04793549  -2.76167083]\n",
      " [ 28.26268196  -1.45644593]\n",
      " [ 28.06295967  -1.13944912]\n",
      " [ 34.24255371  -1.97839367]\n",
      " [ 28.1107235   -1.79178309]\n",
      " [ 40.69409943  -4.1798625 ]\n",
      " [ 43.47127533  -3.58862329]\n",
      " [ 33.10240936  -4.56947756]\n",
      " [ 23.6445713   -2.69055724]\n",
      " [ 44.20451736  -2.6673007 ]\n",
      " [ 42.71046448  -2.7934382 ]\n",
      " [ 37.28145981  -2.51564145]\n",
      " [ 31.16433716  -2.46071815]\n",
      " [ 28.73022652  -2.77424002]\n",
      " [ 37.85688019  -2.76080465]\n",
      " [ 43.85177994  -2.87974834]\n",
      " [ 35.75405121  -2.28774166]\n",
      " [ 37.9142189   -3.10622406]\n",
      " [ 33.3874855   -2.6138773 ]\n",
      " [ 27.96331978  -2.26697993]\n",
      " [ 32.61206055  -1.06613028]\n",
      " [ 35.10255432  -2.88066101]\n",
      " [ 34.39094543  -4.04317617]\n",
      " [ 34.51609039  -3.31586123]\n",
      " [ 35.5759964   -2.44716358]\n",
      " [ 29.86963081  -2.6001029 ]\n",
      " [ 24.01465607  -5.25114965]\n",
      " [ 35.46658325  -3.65985918]\n",
      " [ 24.68895531  -4.84359121]\n",
      " [ 42.00717545  -2.55421352]\n",
      " [ 38.34164047  -3.01809144]\n",
      " [ 45.24016953  -3.85456896]\n",
      " [ 38.77465439  -1.67520869]\n",
      " [ 33.70827866  -5.64316893]\n",
      " [ 27.41215706  -2.79635644]\n",
      " [ 30.39495659  -2.6829567 ]\n",
      " [ 32.59950256  -3.04392529]\n",
      " [ 37.94574738  -2.61358047]\n",
      " [ 33.85882568  -4.70956612]\n",
      " [ 29.00694275  -2.21123075]\n",
      " [ 42.90158081  -2.49557853]]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     tf.add_to_collection('accuracy', accuracy)\n",
    "#     tf.add_to_collection('y_', y_)\n",
    "#     tf.add_to_collection('x_in', x_in)\n",
    "#     tf.add_to_collection('y_in', y_in)\n",
    "#     # writer = tf.summary.FileWriter('./logs',sess.graph)\n",
    "#     for i in range(300):\n",
    "#         minibatch = MiniBatch(train_x, train_y, 50)\n",
    "#         x_batch,y_batch = minibatch.next_batch()\n",
    "#         if x_batch is None or x_batch.shape[0]<30:\n",
    "#             minibatch = MiniBatch(train_x, train_y, 50)\n",
    "#             x_batch,y_batch = minibatch.next_batch()\n",
    "#         print('minibatch size {} and {}'.format(x_batch.shape, y_batch.shape))\n",
    "# #         if i%10 == 0:\n",
    "# #             train_accuracy = accuracy.eval(session=sess,\n",
    "# #                                             feed_dict={\n",
    "# #                                                 x_in:x_batch, y_in:y_batch\n",
    "# #                                             })\n",
    "# #             print('step {}, training accuracy {}'.format(i, train_accuracy))\n",
    "# #         sess.run(optimizer, feed_dict={x_in:x_batch, y_in:y_batch})\n",
    "# #     # writer.close()\n",
    "# #     print('test accuracy {}'.format(accuracy.eval(session=sess, feed_dict={x_in: dev_x , y_in: dev_y})))\n",
    "# #     saver = tf.train.Saver()\n",
    "# #     saved_path = saver.save(sess, './models/1st.ckpt')\n",
    "# #     print('model saved to {}'.format(saved_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.5\n",
      "step 100, training accuracy 0.8999999761581421\n",
      "step 200, training accuracy 0.9599999785423279\n",
      "step 300, training accuracy 0.9800000190734863\n",
      "step 400, training accuracy 1.0\n",
      "test accuracy 0.6433333158493042\n",
      "model saved to ./models/1channel.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf.add_to_collection('accuracy', accuracy)\n",
    "    tf.add_to_collection('y_', y_)\n",
    "    tf.add_to_collection('x_in', x_in)\n",
    "    tf.add_to_collection('y_in', y_in)\n",
    "    # writer = tf.summary.FileWriter('./logs',sess.graph)\n",
    "    for i in range(500):\n",
    "        minibatch = MiniBatch(train_x, train_y, 50)\n",
    "        x_batch,y_batch = minibatch.next_batch()\n",
    "        if x_batch is None or x_batch.shape[0]<30:\n",
    "            minibatch = MiniBatch(train_x, train_y, 50)\n",
    "            x_batch,y_batch = minibatch.next_batch()\n",
    "        # print('minibatch size {} and {}'.format(x_batch.shape, y_batch.shape))\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(session=sess,\n",
    "                                            feed_dict={\n",
    "                                                x_in:x_batch, y_in:y_batch\n",
    "                                            })\n",
    "            print('step {}, training accuracy {}'.format(i, train_accuracy))\n",
    "        sess.run(optimizer, feed_dict={x_in:x_batch, y_in:y_batch})\n",
    "    # writer.close()\n",
    "    print('test accuracy {}'.format(accuracy.eval(session=sess, feed_dict={x_in: dev_x , y_in: dev_y})))\n",
    "    saver = tf.train.Saver()\n",
    "    saved_path = saver.save(sess, './models/1channel.ckpt')\n",
    "    print('model saved to {}'.format(saved_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     saver = tf.train.import_meta_graph('./models/1st.ckpt.meta')\n",
    "#     saver.restore(sess, './models/1st.ckpt')\n",
    "#     accuracy = tf.get_collection('accuracy')[0]\n",
    "#     print('model restored')\n",
    "#     print('test accuracy {}'.format(accuracy.eval(session=sess, feed_dict={x_in:mnist.test.images, y_in:mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
